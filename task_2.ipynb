{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9738863f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "import json\n",
    "import os\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "341586f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path ='input2/people-detection.mp4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d02cd48b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRO TIP  Replace 'model=yolov5s.pt' with new 'model=yolov5su.pt'.\n",
      "YOLOv5 'u' models are trained with https://github.com/ultralytics/ultralytics and feature improved performance vs standard YOLOv5 models trained with https://github.com/ultralytics/yolov5.\n",
      "\n",
      "\n",
      "0: 384x640 (no detections), 236.8ms\n",
      "Speed: 11.3ms preprocess, 236.8ms inference, 5.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 119.2ms\n",
      "Speed: 3.1ms preprocess, 119.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 116.3ms\n",
      "Speed: 2.1ms preprocess, 116.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 122.0ms\n",
      "Speed: 2.4ms preprocess, 122.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 118.0ms\n",
      "Speed: 2.3ms preprocess, 118.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 108.6ms\n",
      "Speed: 1.6ms preprocess, 108.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 111.0ms\n",
      "Speed: 2.2ms preprocess, 111.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 dog, 122.6ms\n",
      "Speed: 2.0ms preprocess, 122.6ms inference, 6.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 109.1ms\n",
      "Speed: 2.1ms preprocess, 109.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 108.1ms\n",
      "Speed: 1.5ms preprocess, 108.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 116.9ms\n",
      "Speed: 1.9ms preprocess, 116.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 117.6ms\n",
      "Speed: 2.8ms preprocess, 117.6ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 112.2ms\n",
      "Speed: 2.5ms preprocess, 112.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.1ms\n",
      "Speed: 1.8ms preprocess, 110.1ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 118.7ms\n",
      "Speed: 2.2ms preprocess, 118.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 108.0ms\n",
      "Speed: 2.4ms preprocess, 108.0ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 115.3ms\n",
      "Speed: 1.9ms preprocess, 115.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 120.5ms\n",
      "Speed: 1.9ms preprocess, 120.5ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 115.4ms\n",
      "Speed: 1.6ms preprocess, 115.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.7ms\n",
      "Speed: 2.4ms preprocess, 110.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.7ms\n",
      "Speed: 1.5ms preprocess, 110.7ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 101.4ms\n",
      "Speed: 2.1ms preprocess, 101.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 111.1ms\n",
      "Speed: 1.5ms preprocess, 111.1ms inference, 36.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 118.2ms\n",
      "Speed: 1.6ms preprocess, 118.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 112.3ms\n",
      "Speed: 2.1ms preprocess, 112.3ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 111.5ms\n",
      "Speed: 2.1ms preprocess, 111.5ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 110.5ms\n",
      "Speed: 2.4ms preprocess, 110.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 109.2ms\n",
      "Speed: 2.0ms preprocess, 109.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 109.3ms\n",
      "Speed: 2.3ms preprocess, 109.3ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 109.3ms\n",
      "Speed: 1.7ms preprocess, 109.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 109.9ms\n",
      "Speed: 2.2ms preprocess, 109.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 110.4ms\n",
      "Speed: 1.7ms preprocess, 110.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 108.2ms\n",
      "Speed: 2.2ms preprocess, 108.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 109.5ms\n",
      "Speed: 2.2ms preprocess, 109.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 111.5ms\n",
      "Speed: 1.7ms preprocess, 111.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 115.6ms\n",
      "Speed: 2.7ms preprocess, 115.6ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 109.1ms\n",
      "Speed: 2.1ms preprocess, 109.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 105.7ms\n",
      "Speed: 2.2ms preprocess, 105.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 109.7ms\n",
      "Speed: 2.1ms preprocess, 109.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 112.1ms\n",
      "Speed: 2.1ms preprocess, 112.1ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 111.8ms\n",
      "Speed: 2.4ms preprocess, 111.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 107.6ms\n",
      "Speed: 2.2ms preprocess, 107.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 106.8ms\n",
      "Speed: 1.8ms preprocess, 106.8ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 105.9ms\n",
      "Speed: 1.7ms preprocess, 105.9ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 104.4ms\n",
      "Speed: 2.3ms preprocess, 104.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 99.7ms\n",
      "Speed: 2.3ms preprocess, 99.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.4ms\n",
      "Speed: 1.8ms preprocess, 92.4ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.5ms\n",
      "Speed: 1.5ms preprocess, 87.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.7ms\n",
      "Speed: 1.3ms preprocess, 90.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 93.9ms\n",
      "Speed: 1.8ms preprocess, 93.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.0ms\n",
      "Speed: 1.7ms preprocess, 83.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 83.6ms\n",
      "Speed: 1.8ms preprocess, 83.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.0ms\n",
      "Speed: 1.4ms preprocess, 88.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 93.5ms\n",
      "Speed: 2.2ms preprocess, 93.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 86.4ms\n",
      "Speed: 1.6ms preprocess, 86.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.7ms\n",
      "Speed: 1.7ms preprocess, 89.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.0ms\n",
      "Speed: 1.2ms preprocess, 92.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.1ms\n",
      "Speed: 1.5ms preprocess, 91.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.8ms\n",
      "Speed: 2.1ms preprocess, 90.8ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 142.7ms\n",
      "Speed: 1.3ms preprocess, 142.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 94.0ms\n",
      "Speed: 1.4ms preprocess, 94.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 87.5ms\n",
      "Speed: 1.5ms preprocess, 87.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 95.1ms\n",
      "Speed: 1.6ms preprocess, 95.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 102.9ms\n",
      "Speed: 2.7ms preprocess, 102.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 93.5ms\n",
      "Speed: 1.6ms preprocess, 93.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 96.1ms\n",
      "Speed: 1.5ms preprocess, 96.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 93.5ms\n",
      "Speed: 1.5ms preprocess, 93.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 93.3ms\n",
      "Speed: 1.7ms preprocess, 93.3ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 95.5ms\n",
      "Speed: 1.5ms preprocess, 95.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 89.9ms\n",
      "Speed: 1.9ms preprocess, 89.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 91.5ms\n",
      "Speed: 1.6ms preprocess, 91.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 91.3ms\n",
      "Speed: 1.4ms preprocess, 91.3ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 handbag, 89.7ms\n",
      "Speed: 1.7ms preprocess, 89.7ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 87.7ms\n",
      "Speed: 1.7ms preprocess, 87.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 91.1ms\n",
      "Speed: 1.5ms preprocess, 91.1ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 handbag, 95.0ms\n",
      "Speed: 1.7ms preprocess, 95.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 4 persons, 103.4ms\n",
      "Speed: 1.4ms preprocess, 103.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 110.3ms\n",
      "Speed: 2.2ms preprocess, 110.3ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 93.9ms\n",
      "Speed: 1.7ms preprocess, 93.9ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 91.7ms\n",
      "Speed: 1.4ms preprocess, 91.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 93.9ms\n",
      "Speed: 1.5ms preprocess, 93.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.5ms\n",
      "Speed: 1.2ms preprocess, 93.5ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 89.4ms\n",
      "Speed: 1.4ms preprocess, 89.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 86.2ms\n",
      "Speed: 1.7ms preprocess, 86.2ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.0ms\n",
      "Speed: 1.9ms preprocess, 90.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.6ms\n",
      "Speed: 2.0ms preprocess, 92.6ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.1ms\n",
      "Speed: 1.8ms preprocess, 92.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.2ms\n",
      "Speed: 1.7ms preprocess, 90.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.3ms\n",
      "Speed: 1.7ms preprocess, 92.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.6ms\n",
      "Speed: 1.7ms preprocess, 88.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.9ms\n",
      "Speed: 2.1ms preprocess, 87.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.5ms\n",
      "Speed: 1.8ms preprocess, 92.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.4ms\n",
      "Speed: 1.5ms preprocess, 95.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.0ms\n",
      "Speed: 1.4ms preprocess, 100.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 105.3ms\n",
      "Speed: 2.0ms preprocess, 105.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 112.7ms\n",
      "Speed: 2.1ms preprocess, 112.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.2ms\n",
      "Speed: 1.8ms preprocess, 92.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.9ms\n",
      "Speed: 1.7ms preprocess, 88.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 120.6ms\n",
      "Speed: 1.5ms preprocess, 120.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 132.4ms\n",
      "Speed: 3.0ms preprocess, 132.4ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 116.1ms\n",
      "Speed: 1.6ms preprocess, 116.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 106.4ms\n",
      "Speed: 2.8ms preprocess, 106.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.9ms\n",
      "Speed: 2.1ms preprocess, 95.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 94.5ms\n",
      "Speed: 1.2ms preprocess, 94.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.0ms\n",
      "Speed: 1.7ms preprocess, 95.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 93.9ms\n",
      "Speed: 1.7ms preprocess, 93.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 94.5ms\n",
      "Speed: 1.4ms preprocess, 94.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.8ms\n",
      "Speed: 1.5ms preprocess, 100.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 115.5ms\n",
      "Speed: 1.3ms preprocess, 115.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.1ms\n",
      "Speed: 1.7ms preprocess, 100.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.2ms\n",
      "Speed: 2.0ms preprocess, 92.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 89.2ms\n",
      "Speed: 1.8ms preprocess, 89.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 97.7ms\n",
      "Speed: 2.1ms preprocess, 97.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 93.6ms\n",
      "Speed: 1.7ms preprocess, 93.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 90.5ms\n",
      "Speed: 1.7ms preprocess, 90.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 1 dog, 90.8ms\n",
      "Speed: 1.3ms preprocess, 90.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 2 toilets, 91.6ms\n",
      "Speed: 1.5ms preprocess, 91.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 92.0ms\n",
      "Speed: 1.3ms preprocess, 92.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 89.7ms\n",
      "Speed: 1.4ms preprocess, 89.7ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 90.1ms\n",
      "Speed: 1.4ms preprocess, 90.1ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 91.0ms\n",
      "Speed: 1.5ms preprocess, 91.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 sports ball, 88.9ms\n",
      "Speed: 2.0ms preprocess, 88.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[ALERT] Crowd detected at frame 363 (2025-07-13 23:20:56)\n",
      "\n",
      "0: 384x640 3 persons, 1 sports ball, 94.3ms\n",
      "Speed: 1.7ms preprocess, 94.3ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 111.0ms\n",
      "Speed: 1.7ms preprocess, 111.0ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 105.5ms\n",
      "Speed: 1.7ms preprocess, 105.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 98.2ms\n",
      "Speed: 2.0ms preprocess, 98.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 1 skateboard, 100.8ms\n",
      "Speed: 1.9ms preprocess, 100.8ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[ALERT] Crowd detected at frame 378 (2025-07-13 23:20:57)\n",
      "\n",
      "0: 384x640 4 persons, 101.7ms\n",
      "Speed: 1.4ms preprocess, 101.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 100.5ms\n",
      "Speed: 1.8ms preprocess, 100.5ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 96.6ms\n",
      "Speed: 1.8ms preprocess, 96.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 93.6ms\n",
      "Speed: 2.0ms preprocess, 93.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 91.7ms\n",
      "Speed: 1.7ms preprocess, 91.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "[ALERT] Crowd detected at frame 393 (2025-07-13 23:20:57)\n",
      "\n",
      "0: 384x640 3 persons, 87.9ms\n",
      "Speed: 1.5ms preprocess, 87.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 3 persons, 108.0ms\n",
      "Speed: 2.2ms preprocess, 108.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 90.0ms\n",
      "Speed: 1.9ms preprocess, 90.0ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 92.9ms\n",
      "Speed: 1.5ms preprocess, 92.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 110.8ms\n",
      "Speed: 1.3ms preprocess, 110.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 chair, 153.6ms\n",
      "Speed: 2.6ms preprocess, 153.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 128.0ms\n",
      "Speed: 2.9ms preprocess, 128.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 109.4ms\n",
      "Speed: 2.5ms preprocess, 109.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 106.6ms\n",
      "Speed: 1.8ms preprocess, 106.6ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 112.2ms\n",
      "Speed: 1.8ms preprocess, 112.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 105.4ms\n",
      "Speed: 1.7ms preprocess, 105.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 103.1ms\n",
      "Speed: 1.9ms preprocess, 103.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 105.3ms\n",
      "Speed: 2.2ms preprocess, 105.3ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 107.4ms\n",
      "Speed: 1.6ms preprocess, 107.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 129.2ms\n",
      "Speed: 1.7ms preprocess, 129.2ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 112.4ms\n",
      "Speed: 2.1ms preprocess, 112.4ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 98.1ms\n",
      "Speed: 1.5ms preprocess, 98.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 100.5ms\n",
      "Speed: 1.7ms preprocess, 100.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 112.1ms\n",
      "Speed: 1.8ms preprocess, 112.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.1ms\n",
      "Speed: 1.7ms preprocess, 91.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 126.5ms\n",
      "Speed: 2.0ms preprocess, 126.5ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 129.2ms\n",
      "Speed: 2.0ms preprocess, 129.2ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 115.0ms\n",
      "Speed: 1.8ms preprocess, 115.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 102.2ms\n",
      "Speed: 2.2ms preprocess, 102.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 103.0ms\n",
      "Speed: 1.8ms preprocess, 103.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 102.0ms\n",
      "Speed: 1.3ms preprocess, 102.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 170.0ms\n",
      "Speed: 1.7ms preprocess, 170.0ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 147.5ms\n",
      "Speed: 13.5ms preprocess, 147.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.3ms\n",
      "Speed: 1.6ms preprocess, 85.3ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.9ms\n",
      "Speed: 1.8ms preprocess, 90.9ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.5ms\n",
      "Speed: 1.7ms preprocess, 80.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.7ms\n",
      "Speed: 1.8ms preprocess, 82.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.0ms\n",
      "Speed: 1.3ms preprocess, 85.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.5ms\n",
      "Speed: 1.7ms preprocess, 90.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 92.8ms\n",
      "Speed: 1.5ms preprocess, 92.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 88.4ms\n",
      "Speed: 1.7ms preprocess, 88.4ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 94.1ms\n",
      "Speed: 2.1ms preprocess, 94.1ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.7ms\n",
      "Speed: 1.8ms preprocess, 81.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 80.5ms\n",
      "Speed: 1.7ms preprocess, 80.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 81.0ms\n",
      "Speed: 1.8ms preprocess, 81.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 82.7ms\n",
      "Speed: 1.7ms preprocess, 82.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 79.7ms\n",
      "Speed: 1.8ms preprocess, 79.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.7ms\n",
      "Speed: 1.8ms preprocess, 83.7ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.5ms\n",
      "Speed: 1.4ms preprocess, 81.5ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 82.8ms\n",
      "Speed: 1.9ms preprocess, 82.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 83.3ms\n",
      "Speed: 1.7ms preprocess, 83.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 85.6ms\n",
      "Speed: 1.3ms preprocess, 85.6ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 81.1ms\n",
      "Speed: 1.6ms preprocess, 81.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 88.5ms\n",
      "Speed: 1.7ms preprocess, 88.5ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 87.8ms\n",
      "Speed: 1.6ms preprocess, 87.8ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 91.2ms\n",
      "Speed: 1.9ms preprocess, 91.2ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 105.1ms\n",
      "Speed: 1.8ms preprocess, 105.1ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 2 persons, 91.7ms\n",
      "Speed: 1.8ms preprocess, 91.7ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 96.4ms\n",
      "Speed: 2.0ms preprocess, 96.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 1 person, 103.7ms\n",
      "Speed: 2.0ms preprocess, 103.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.5ms\n",
      "Speed: 1.4ms preprocess, 91.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.2ms\n",
      "Speed: 1.7ms preprocess, 87.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 85.0ms\n",
      "Speed: 1.7ms preprocess, 85.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 117.1ms\n",
      "Speed: 1.7ms preprocess, 117.1ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 91.7ms\n",
      "Speed: 1.9ms preprocess, 91.7ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 94.8ms\n",
      "Speed: 1.4ms preprocess, 94.8ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 94.2ms\n",
      "Speed: 1.7ms preprocess, 94.2ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 95.5ms\n",
      "Speed: 1.9ms preprocess, 95.5ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 97.8ms\n",
      "Speed: 1.3ms preprocess, 97.8ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 90.0ms\n",
      "Speed: 1.4ms preprocess, 90.0ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 87.0ms\n",
      "Speed: 1.4ms preprocess, 87.0ms inference, 0.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "0: 384x640 (no detections), 84.3ms\n",
      "Speed: 1.7ms preprocess, 84.3ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "\n",
      "Total Alerts Triggered: 3\n",
      "Sample Alert: {'frame': 363, 'timestamp': '2025-07-13 23:20:56', 'message': 'Crowd Detected'}\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov5s.pt\")\n",
    "\n",
    "frame_skip = 3\n",
    "alert_threshold = 3\n",
    "alert_window = 5\n",
    "alert_log_path = \"alert_log.json\"\n",
    "timeline_plot_path = \"alert_timeline.png\"\n",
    "\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "frame_id = 0\n",
    "recent_people_counts = deque(maxlen=alert_window)\n",
    "alert_times = []\n",
    "alerts = []\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if frame_id % frame_skip == 0:\n",
    "        results = model(frame)[0]\n",
    "        person_count = 0\n",
    "\n",
    "        for box in results.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            label = model.names[cls_id]\n",
    "            if label == \"person\":\n",
    "                person_count += 1\n",
    "\n",
    "        recent_people_counts.append(person_count)\n",
    "\n",
    "        if len(recent_people_counts) == alert_window and all(p >= alert_threshold for p in recent_people_counts):\n",
    "            timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "            alert_msg = {\n",
    "                \"frame\": frame_id,\n",
    "                \"timestamp\": timestamp,\n",
    "                \"message\": \"Crowd Detected\"\n",
    "            }\n",
    "            alerts.append(alert_msg)\n",
    "            alert_times.append(frame_id)\n",
    "            print(f\"[ALERT] Crowd detected at frame {frame_id} ({timestamp})\")\n",
    "            recent_people_counts.clear()\n",
    "\n",
    "    frame_id += 1\n",
    "\n",
    "cap.release()\n",
    "\n",
    "with open(alert_log_path, 'w') as f:\n",
    "    json.dump(alerts, f, indent=2)\n",
    "\n",
    "print(f\"\\nTotal Alerts Triggered: {len(alerts)}\")\n",
    "if alerts:\n",
    "    print(\"Sample Alert:\", alerts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dc296ff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10, 4))\n",
    "plt.scatter(alert_times, [1]*len(alert_times), color='red', label='Crowd Detected')\n",
    "plt.title(\"Alert Timeline\")\n",
    "plt.xlabel(\"Frame ID\")\n",
    "plt.yticks([])\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.savefig(timeline_plot_path)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d639ff",
   "metadata": {},
   "source": [
    "## How I did it – Step-by-step:\n",
    "\n",
    "\n",
    "1. Loaded the video using OpenCV from the given local path.\n",
    "\n",
    "2. Loaded the YOLOv5 model to detect objects, especially focusing on people.\n",
    "\n",
    "3. Processed every 3rd frame from the video to simulate a real-time stream.\n",
    "\n",
    "4. For each processed frame:\n",
    "\n",
    "- Ran object detection using YOLOv5.\n",
    "\n",
    "- Counted how many people (label == \"person\") were detected.\n",
    "\n",
    "- Saved this count in a rolling window of the last 5 frames.\n",
    "\n",
    "5. If 3 or more people appeared in 5 consecutive frames, triggered an alert:\n",
    "\n",
    "- Captured the frame number and timestamp.\n",
    "\n",
    "- Logged the alert in a list.\n",
    "\n",
    "6. After processing the video:\n",
    "\n",
    "- Saved all alert data in a .json file.\n",
    "\n",
    "- Counted the total number of alerts.\n",
    "\n",
    "7. Created a timeline scatter plot:\n",
    "\n",
    "- Each red dot shows a frame where a crowd was detected.\n",
    "\n",
    "8. Saved all results:\n",
    "\n",
    "- Alert log in .json\n",
    "\n",
    "- Timeline chart in .png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25620620",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
